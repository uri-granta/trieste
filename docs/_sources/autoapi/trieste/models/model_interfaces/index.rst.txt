:orphan:

:mod:`trieste.models.model_interfaces`
======================================

.. py:module:: trieste.models.model_interfaces


Module Contents
---------------

.. class:: ProbabilisticModel

   Bases: :py:obj:`abc.ABC`

   A probabilistic model. 

   .. method:: predict(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]
      :abstractmethod:

      Return the mean and variance of the independent marginal distributions at each point in
      ``query_points``.

      This is essentially a convenience method for :meth:`predict_joint`, where non-event
      dimensions of ``query_points`` are all interpreted as broadcasting dimensions instead of
      batch dimensions, and the covariance is squeezed to remove redundant nesting.

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The mean and variance of the independent marginal distributions at each point in
          ``query_points``. For a predictive distribution with event shape E, the mean and
          variance will both have shape [...] + E.


   .. method:: predict_joint(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]
      :abstractmethod:

      :param query_points: The points at which to make predictions, of shape [..., B, D].
      :return: The mean and covariance of the joint marginal distribution at each batch of points
          in ``query_points``. For a predictive distribution with event shape E, the mean will
          have shape [..., B] + E, and the covariance shape [...] + E + [B, B].


   .. method:: sample(self, query_points: trieste.type.TensorType, num_samples: int) -> trieste.type.TensorType
      :abstractmethod:

      Return ``num_samples`` samples from the independent marginal distributions at
      ``query_points``.

      :param query_points: The points at which to sample, with shape [..., N, D].
      :param num_samples: The number of samples at each point.
      :return: The samples. For a predictive distribution with event shape E, this has shape
          [..., S, N] + E, where S is the number of samples.


   .. method:: predict_y(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]
      :abstractmethod:

      Return the mean and variance of the independent marginal distributions at each point in
      ``query_points`` for the observations, including noise contributions.

      Note that this is not supported by all models.

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The mean and variance of the independent marginal distributions at each point in
          ``query_points``. For a predictive distribution with event shape E, the mean and
          variance will both have shape [...] + E.



.. class:: TrainableProbabilisticModel

   Bases: :py:obj:`ProbabilisticModel`

   A trainable probabilistic model. 

   .. method:: update(self, dataset: trieste.data.Dataset) -> None
      :abstractmethod:

      Update the model given the specified ``dataset``. Does not train the model.

      :param dataset: The data with which to update the model.


   .. method:: optimize(self, dataset: trieste.data.Dataset) -> None
      :abstractmethod:

      Optimize the model objective with respect to (hyper)parameters given the specified
      ``dataset``.

      :param dataset: The data with which to train the model.



.. class:: ModelStack(model_with_event_size: tuple[TrainableProbabilisticModel, int], *models_with_event_sizes: tuple[TrainableProbabilisticModel, int])


   Bases: :py:obj:`TrainableProbabilisticModel`

   A :class:`ModelStack` is a wrapper around a number of :class:`TrainableProbabilisticModel`\ s.
   It combines the outputs of each model for predictions and sampling, and delegates training data
   to each model for updates and optimization.

   **Note:** Only supports vector outputs (i.e. with event shape [E]). Outputs for any two models
   are assumed independent. Each model may itself be single- or multi-output, and any one
   multi-output model may have dependence between its outputs. When we speak of *event size* in
   this class, we mean the output dimension for a given :class:`TrainableProbabilisticModel`,
   whether that is the :class:`ModelStack` itself, or one of the subsidiary
   :class:`TrainableProbabilisticModel`\ s within the :class:`ModelStack`. Of course, the event
   size for a :class:`ModelStack` will be the sum of the event sizes of each subsidiary model.

   The order of individual models specified at :meth:`__init__` determines the order of the
   :class:`ModelStack` output dimensions.

   :param model_with_event_size: The first model, and the size of its output events.
       **Note:** This is a separate parameter to ``models_with_event_sizes`` simply so that the
       method signature requires at least one model. It is not treated specially.
   :param \*models_with_event_sizes: The other models, and sizes of their output events.

   .. method:: predict(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The predictions from all the wrapped models, concatenated along the event axis in
          the same order as they appear in :meth:`__init__`. If the wrapped models have predictive
          distributions with event shapes [:math:`E_i`], the mean and variance will both have
          shape [..., :math:`\sum_i E_i`].


   .. method:: predict_joint(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      :param query_points: The points at which to make predictions, of shape [..., B, D].
      :return: The predictions from all the wrapped models, concatenated along the event axis in
          the same order as they appear in :meth:`__init__`. If the wrapped models have predictive
          distributions with event shapes [:math:`E_i`], the mean will have shape
          [..., B, :math:`\sum_i E_i`], and the covariance shape
          [..., :math:`\sum_i E_i`, B, B].


   .. method:: sample(self, query_points: trieste.type.TensorType, num_samples: int) -> trieste.type.TensorType

      :param query_points: The points at which to sample, with shape [..., N, D].
      :param num_samples: The number of samples at each point.
      :return: The samples from all the wrapped models, concatenated along the event axis. For
          wrapped models with predictive distributions with event shapes [:math:`E_i`], this has
          shape [..., S, N, :math:`\sum_i E_i`], where S is the number of samples.


   .. method:: predict_y(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The predictions from all the wrapped models, concatenated along the event axis in
          the same order as they appear in :meth:`__init__`. If the wrapped models have predictive
          distributions with event shapes [:math:`E_i`], the mean and variance will both have
          shape [..., :math:`\sum_i E_i`].
      :raise NotImplementedError: If any of the models don't implement predict_y.


   .. method:: update(self, dataset: trieste.data.Dataset) -> None

      Update all the wrapped models on their corresponding data. The data for each model is
      extracted by splitting the observations in ``dataset`` along the event axis according to the
      event sizes specified at :meth:`__init__`.

      :param dataset: The query points and observations for *all* the wrapped models.


   .. method:: optimize(self, dataset: trieste.data.Dataset) -> None

      Optimize all the wrapped models on their corresponding data. The data for each model is
      extracted by splitting the observations in ``dataset`` along the event axis according to the
      event sizes specified at :meth:`__init__`.

      :param dataset: The query points and observations for *all* the wrapped models.



.. data:: M
   

   A type variable bound to :class:`tf.Module`. 


.. function:: module_deepcopy(self: M, memo: dict[int, object]) -> M

   This function provides a workaround for `a bug`_ in TensorFlow Probability (fixed in `version
   0.12`_) where a :class:`tf.Module` cannot be deep-copied if it has
   :class:`tfp.bijectors.Bijector` instances on it. The function can be used to directly copy an
   object ``self`` as e.g. ``module_deepcopy(self, {})``, but it is perhaps more useful as an
   implemention for :meth:`__deepcopy__` on classes, where it can be used as follows:

   .. _a bug: https://github.com/tensorflow/probability/issues/547
   .. _version 0.12: https://github.com/tensorflow/probability/releases/tag/v0.12.1

   .. testsetup:: *

       >>> import tensorflow_probability as tfp

   >>> class Foo(tf.Module):
   ...     example_bijector = tfp.bijectors.Exp()
   ...
   ...     __deepcopy__ = module_deepcopy

   Classes with this method can be deep-copied even if they contain
   :class:`tfp.bijectors.Bijector`\ s.

   :param self: The object to copy.
   :param memo: References to existing deep-copied objects (by object :func:`id`).
   :return: A deep-copy of ``self``.


.. class:: GPflowPredictor(optimizer: Optimizer | None = None)


   Bases: :py:obj:`ProbabilisticModel`, :py:obj:`tensorflow.Module`, :py:obj:`abc.ABC`

   A trainable wrapper for a GPflow Gaussian process model. 

   :param optimizer: The optimizer with which to train the model. Defaults to
       :class:`~trieste.models.optimizer.Optimizer` with :class:`~gpflow.optimizers.Scipy`.

   .. method:: optimizer(self) -> trieste.models.optimizer.Optimizer
      :property:

      The optimizer with which to train the model. 


   .. method:: model(self) -> gpflow.models.GPModel
      :property:

      The underlying GPflow model. 


   .. method:: predict(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      Return the mean and variance of the independent marginal distributions at each point in
      ``query_points``.

      This is essentially a convenience method for :meth:`predict_joint`, where non-event
      dimensions of ``query_points`` are all interpreted as broadcasting dimensions instead of
      batch dimensions, and the covariance is squeezed to remove redundant nesting.

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The mean and variance of the independent marginal distributions at each point in
          ``query_points``. For a predictive distribution with event shape E, the mean and
          variance will both have shape [...] + E.


   .. method:: predict_joint(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      :param query_points: The points at which to make predictions, of shape [..., B, D].
      :return: The mean and covariance of the joint marginal distribution at each batch of points
          in ``query_points``. For a predictive distribution with event shape E, the mean will
          have shape [..., B] + E, and the covariance shape [...] + E + [B, B].


   .. method:: sample(self, query_points: trieste.type.TensorType, num_samples: int) -> trieste.type.TensorType

      Return ``num_samples`` samples from the independent marginal distributions at
      ``query_points``.

      :param query_points: The points at which to sample, with shape [..., N, D].
      :param num_samples: The number of samples at each point.
      :return: The samples. For a predictive distribution with event shape E, this has shape
          [..., S, N] + E, where S is the number of samples.


   .. method:: predict_y(self, query_points: trieste.type.TensorType) -> tuple[trieste.type.TensorType, trieste.type.TensorType]

      Return the mean and variance of the independent marginal distributions at each point in
      ``query_points`` for the observations, including noise contributions.

      Note that this is not supported by all models.

      :param query_points: The points at which to make predictions, of shape [..., D].
      :return: The mean and variance of the independent marginal distributions at each point in
          ``query_points``. For a predictive distribution with event shape E, the mean and
          variance will both have shape [...] + E.


   .. method:: optimize(self, dataset: trieste.data.Dataset) -> None

      Optimize the model with the specified `dataset`.

      :param dataset: The data with which to optimize the `model`.



.. class:: GaussianProcessRegression(model: GPR | SGPR, optimizer: Optimizer | None = None)


   Bases: :py:obj:`GPflowPredictor`, :py:obj:`TrainableProbabilisticModel`

   A :class:`TrainableProbabilisticModel` wrapper for a GPflow :class:`~gpflow.models.GPR`
   or :class:`~gpflow.models.SGPR`.

   :param model: The GPflow model to wrap.
   :param optimizer: The optimizer with which to train the model. Defaults to
       :class:`~trieste.models.optimizer.Optimizer` with :class:`~gpflow.optimizers.Scipy`.

   .. method:: model(self) -> GPR | SGPR
      :property:

      The underlying GPflow model. 


   .. method:: update(self, dataset: trieste.data.Dataset) -> None

      Update the model given the specified ``dataset``. Does not train the model.

      :param dataset: The data with which to update the model.


   .. method:: covariance_between_points(self, query_points_1: trieste.type.TensorType, query_points_2: trieste.type.TensorType) -> trieste.type.TensorType

      Compute the posterior covariance between sets of query points.

      .. math:: \Sigma_{12} = K_{12} - K_{x1}(K_{xx} + \sigma^2 I)^{-1}K_{x2}

      :param query_points_1: Set of query points with shape [N, D]
      :param query_points_2: Sets of query points with shape [M, D]

      :return: Covariance matrix between the sets of query points with shape [N, M]



.. class:: SparseVariational(model: gpflow.models.SVGP, data: trieste.data.Dataset, optimizer: Optimizer | None = None)


   Bases: :py:obj:`GPflowPredictor`, :py:obj:`TrainableProbabilisticModel`

   A :class:`TrainableProbabilisticModel` wrapper for a GPflow :class:`~gpflow.models.SVGP`.

   :param model: The underlying GPflow sparse variational model.
   :param data: The initial training data.
   :param optimizer: The optimizer with which to train the model. Defaults to
       :class:`~trieste.models.optimizer.Optimizer` with :class:`~gpflow.optimizers.Scipy`.

   .. method:: model(self) -> gpflow.models.SVGP
      :property:

      The underlying GPflow model. 


   .. method:: update(self, dataset: trieste.data.Dataset) -> None

      Update the model given the specified ``dataset``. Does not train the model.

      :param dataset: The data with which to update the model.



.. class:: VariationalGaussianProcess(model: gpflow.models.VGP, optimizer: Optimizer | None = None)


   Bases: :py:obj:`GPflowPredictor`, :py:obj:`TrainableProbabilisticModel`

   A :class:`TrainableProbabilisticModel` wrapper for a GPflow :class:`~gpflow.models.VGP`. 

   :param model: The GPflow :class:`~gpflow.models.VGP`.
   :param optimizer: The optimizer with which to train the model. Defaults to
       :class:`~trieste.models.optimizer.Optimizer` with :class:`~gpflow.optimizers.Scipy`.
   :raise ValueError (or InvalidArgumentError): If ``model``'s :attr:`q_sqrt` is not rank 3.

   .. method:: model(self) -> gpflow.models.VGP
      :property:

      The underlying GPflow model. 


   .. method:: update(self, dataset: trieste.data.Dataset, *, jitter: float = DEFAULTS.JITTER) -> None

      Update the model given the specified ``dataset``. Does not train the model.

      :param dataset: The data with which to update the model.
      :param jitter: The size of the jitter to use when stabilising the Cholesky decomposition of
          the covariance matrix.



.. data:: supported_models
   :annotation: :dict[Any, collections.abc.Callable[[Any, trieste.models.optimizer.Optimizer], TrainableProbabilisticModel]]

   A mapping of third-party model types to :class:`CustomTrainable` classes that wrap models of those
   types.


